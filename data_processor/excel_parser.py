"""
Excelæ•°æ®è§£ææ¨¡å—
"""
import os
import re
import logging
from datetime import datetime
from typing import Tuple, Optional
import pandas as pd
import openpyxl


class ExcelParser:
    """Excelæ–‡ä»¶è§£æå™¨"""
    
    @staticmethod
    def extract_date_from_filename(filename: str) -> Optional[str]:
        """
        ä»æ–‡ä»¶åæå–æ—¥æœŸ
        
        Args:
            filename: æ–‡ä»¶åï¼Œä¾‹å¦‚ "2025-09-01.xlsx" æˆ– "2025-09-01-5142.xlsx"
            
        Returns:
            æ—¥æœŸå­—ç¬¦ä¸² "YYYY-MM-DD" æˆ– None
        """
        # æå–YYYY-MM-DDæ ¼å¼çš„æ—¥æœŸ
        match = re.search(r'(\d{4})-(\d{2})-(\d{2})', filename)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # å°è¯•æå–YYYY/MM/DDæ ¼å¼
        match = re.search(r'(\d{4})[/\\](\d{2})[/\\](\d{2})', filename)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        return None
    
    @staticmethod
    def parse_excel(file_path: str, column_mapping: dict = None) -> Tuple[pd.DataFrame, str]:
        """
        è§£æExcelæ–‡ä»¶
        
        Args:
            file_path: Excelæ–‡ä»¶è·¯å¾„
            column_mapping: åˆ—åæ˜ å°„å­—å…¸
            
        Returns:
            (DataFrame, äº¤æ˜“æ—¥æœŸ)
        """
        try:
            # è¯»å–Excelæ–‡ä»¶
            if file_path.endswith('.xlsx'):
                df = pd.read_excel(file_path, engine='openpyxl')
            elif file_path.endswith('.xls'):
                df = pd.read_excel(file_path, engine='xlrd')
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
            
            filename = os.path.basename(file_path)
            
            # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæ‰“å°ExcelåŸå§‹ä¿¡æ¯
            logging.info(f"\n{'='*80}")
            logging.info(f"ğŸ“ å¼€å§‹è§£æExcelæ–‡ä»¶: {filename}")
            logging.info(f"{'='*80}")
            logging.info(f"ğŸ“Š Excelæ•°æ®å½¢çŠ¶: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
            logging.info(f"ğŸ“‹ Excelåˆ—ååˆ—è¡¨ï¼ˆå…±{len(df.columns)}åˆ—ï¼‰:")
            for i, col in enumerate(df.columns, 1):
                logging.info(f"    {i:2d}. {col}")
            
            # æ‰“å°ç¬¬ä¸€è¡Œæ•°æ®ä½œä¸ºæ ·æœ¬
            if len(df) > 0:
                logging.info(f"\nğŸ’¡ ç¬¬ä¸€è¡Œæ•°æ®ç¤ºä¾‹:")
                for col in df.columns[:10]:  # åªæ˜¾ç¤ºå‰10åˆ—
                    value = df[col].iloc[0]
                    logging.info(f"    {col}: {value}")
                if len(df.columns) > 10:
                    logging.info(f"    ... (è¿˜æœ‰ {len(df.columns)-10} åˆ—)")
            
            # ä»æ–‡ä»¶åæå–æ—¥æœŸ
            trade_date = ExcelParser.extract_date_from_filename(filename)
            
            if not trade_date:
                logging.warning(f"âš ï¸  æ— æ³•ä»æ–‡ä»¶åæå–æ—¥æœŸ: {filename}")
                # å°è¯•ä»æ•°æ®ä¸­è·å–æ—¥æœŸ
                if 'äº¤æ˜“æ—¥æœŸ' in df.columns:
                    first_date = df['äº¤æ˜“æ—¥æœŸ'].iloc[0]
                    if pd.notna(first_date):
                        trade_date = str(first_date).split()[0]
                        logging.info(f"âœ“ ä»æ•°æ®åˆ—ä¸­è·å–æ—¥æœŸ: {trade_date}")
            else:
                logging.info(f"âœ“ ä»æ–‡ä»¶åæå–æ—¥æœŸ: {trade_date}")
            
            # æ•°æ®æ ‡å‡†åŒ–
            df_normalized = ExcelParser._normalize_data(df, column_mapping, filename)
            
            logging.info(f"\nâœ… Excelè§£æå®Œæˆ: {filename}")
            logging.info(f"   - å¯¼å…¥è®°å½•æ•°: {len(df_normalized)}")
            logging.info(f"   - äº¤æ˜“æ—¥æœŸ: {trade_date}")
            logging.info(f"{'='*80}\n")
            
            return df_normalized, trade_date
            
        except Exception as e:
            logging.error(f"âŒ è§£æExcelå¤±è´¥: {file_path}")
            logging.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}", exc_info=True)
            raise
    
    @staticmethod
    def _normalize_data(df: pd.DataFrame, column_mapping: dict = None, filename: str = "") -> pd.DataFrame:
        """
        æ•°æ®æ ‡å‡†åŒ–å¤„ç†
        
        Args:
            df: åŸå§‹DataFrame
            column_mapping: åˆ—åæ˜ å°„
            filename: æ–‡ä»¶åï¼ˆç”¨äºæ—¥å¿—ï¼‰
            
        Returns:
            æ ‡å‡†åŒ–åçš„DataFrame
        """
        if column_mapping is None:
            column_mapping = {}
        
        logging.info(f"\nğŸ”„ å¼€å§‹åˆ—åæ˜ å°„...")
        
        # åˆ›å»ºæ–°çš„DataFrame
        normalized_df = pd.DataFrame()
        
        # è®°å½•æ˜ å°„æƒ…å†µ
        mapped_count = 0
        unmapped_excel_cols = []
        
        # âœ… ä¿®å¤ï¼šéå†Excelçš„æ¯ä¸€åˆ—ï¼Œè€Œä¸æ˜¯éå†é…ç½®æ–‡ä»¶
        for excel_col in df.columns:
            if excel_col in column_mapping:
                db_col = column_mapping[excel_col]
                # å¦‚æœç›®æ ‡åˆ—è¿˜æ²¡æœ‰æ•°æ®ï¼Œæ‰è¿›è¡Œæ˜ å°„ï¼ˆé¿å…é‡å¤æ˜ å°„è¦†ç›–ï¼‰
                if db_col not in normalized_df.columns:
                    normalized_df[db_col] = df[excel_col].copy()
                    logging.info(f"    âœ“ æ˜ å°„: '{excel_col}' -> '{db_col}'")
                    mapped_count += 1
                else:
                    logging.info(f"    âš ï¸  è·³è¿‡: '{excel_col}' -> '{db_col}' (ç›®æ ‡åˆ—å·²å­˜åœ¨)")
            else:
                unmapped_excel_cols.append(excel_col)
        
        # è®°å½•æœªæ˜ å°„çš„åˆ—
        if unmapped_excel_cols:
            logging.warning(f"\nâš ï¸  ä»¥ä¸‹Excelåˆ—æœªé…ç½®æ˜ å°„ï¼ˆå°†è¢«å¿½ç•¥ï¼‰:")
            for col in unmapped_excel_cols:
                logging.warning(f"    - {col}")
        
        logging.info(f"\nğŸ“Š åˆ—æ˜ å°„ç»Ÿè®¡:")
        logging.info(f"    - Excelæ€»åˆ—æ•°: {len(df.columns)}")
        logging.info(f"    - æˆåŠŸæ˜ å°„: {mapped_count} åˆ—")
        logging.info(f"    - æœªæ˜ å°„: {len(unmapped_excel_cols)} åˆ—")
        logging.info(f"    - ç»“æœåˆ—æ•°: {len(normalized_df.columns)}")
        
        # æ•°æ®æ¸…æ´—
        logging.info(f"\nğŸ§¹ å¼€å§‹æ•°æ®æ¸…æ´—...")
        normalized_df = ExcelParser._clean_data(normalized_df)
        
        # æ‰“å°æ¸…æ´—åçš„ç¤ºä¾‹æ•°æ®
        if len(normalized_df) > 0:
            logging.info(f"\nğŸ’¾ æ¸…æ´—åçš„æ•°æ®ç¤ºä¾‹ï¼ˆç¬¬ä¸€è¡Œï¼‰:")
            for col in normalized_df.columns[:10]:
                value = normalized_df[col].iloc[0]
                logging.info(f"    {col}: {value}")
            if len(normalized_df.columns) > 10:
                logging.info(f"    ... (è¿˜æœ‰ {len(normalized_df.columns)-10} åˆ—)")
        
        return normalized_df
    
    @staticmethod
    def _clean_data(df: pd.DataFrame) -> pd.DataFrame:
        """
        æ•°æ®æ¸…æ´—
        
        Args:
            df: DataFrame
            
        Returns:
            æ¸…æ´—åçš„DataFrame
        """
        # å¤„ç†è‚¡ç¥¨ä»£ç ï¼ˆç¡®ä¿æ˜¯6ä½å­—ç¬¦ä¸²ï¼Œå‰å¯¼é›¶ï¼‰
        if 'stock_code' in df.columns:
            df['stock_code'] = df['stock_code'].apply(
                lambda x: str(int(x)).zfill(6) if pd.notna(x) and str(x).replace('.', '').isdigit() else str(x)
            )
        
        # å¤„ç†æ•°å€¼å­—æ®µï¼Œç§»é™¤"ä¸‡"ã€"äº¿"ç­‰å•ä½
        numeric_columns = [
            'current_price', 'price_change', 'auction_net_amount', 'auction_main_net',
            'auction_today_volume', 'auction_yesterday_volume',
            'main_net_amount', 'real_market_value', 'main_net_ratio', 'flow_ratio',
            'net_ratio', 'buy_sell_ratio', 'turnover_rate', 'real_turnover_rate',
            'volume_ratio', 'popularity_value', 'popularity_change'
        ]
        
        for col in numeric_columns:
            if col in df.columns:
                df[col] = df[col].apply(ExcelParser._parse_numeric)
        
        # å¤„ç†ç«ä»·å¢é¢å­—æ®µï¼ˆä¿ç•™åŸå§‹æ–‡æœ¬ï¼Œå¦‚ "2+", "3+", "5+"ï¼‰
        if 'auction_increase' in df.columns:
            df['auction_increase'] = df['auction_increase'].astype(str).replace('nan', '')
        
        return df
    
    @staticmethod
    def _parse_numeric(value) -> Optional[float]:
        """
        è§£ææ•°å€¼ï¼ˆå¤„ç†å¸¦å•ä½çš„æ•°å€¼ï¼Œå¦‚"1000ä¸‡"ã€"1.2äº¿"ï¼‰
        
        Args:
            value: åŸå§‹å€¼
            
        Returns:
            æµ®ç‚¹æ•°æˆ–None
        """
        if pd.isna(value) or value == '' or value is None:
            return None
        
        try:
            # å¦‚æœå·²ç»æ˜¯æ•°å€¼ç±»å‹
            if isinstance(value, (int, float)):
                return float(value)
            
            # å­—ç¬¦ä¸²å¤„ç†
            str_value = str(value).strip()
            original_value = str_value  # ä¿å­˜åŸå§‹å€¼ç”¨äºæ—¥å¿—
            
            # å¤„ç†äº¿å•ä½ï¼ˆ1äº¿ = 10000ä¸‡ï¼‰
            if 'äº¿' in str_value:
                str_value = str_value.replace('äº¿', '').replace(',', '').strip()
                if str_value and str_value != '-':
                    result = float(str_value) * 10000  # è½¬æ¢ä¸ºä¸‡
                    # logging.debug(f"    æ•°å€¼è½¬æ¢: '{original_value}' -> {result} (äº¿è½¬ä¸‡)")
                    return result
            
            # å¤„ç†ä¸‡å•ä½
            if 'ä¸‡' in str_value:
                str_value = str_value.replace('ä¸‡', '').replace(',', '').strip()
                if str_value and str_value != '-':
                    result = float(str_value)
                    # logging.debug(f"    æ•°å€¼è½¬æ¢: '{original_value}' -> {result}")
                    return result
            
            # ç§»é™¤å…¶ä»–å¸¸è§ç¬¦å·
            str_value = str_value.replace(',', '').replace('%', '').strip()
            
            # å¤„ç†ç©ºå­—ç¬¦ä¸²
            if not str_value or str_value == '-':
                return None
            
            result = float(str_value)
            # logging.debug(f"    æ•°å€¼è½¬æ¢: '{original_value}' -> {result}")
            return result
            
        except (ValueError, TypeError) as e:
            logging.warning(f"    âš ï¸  æ— æ³•è§£ææ•°å€¼: '{value}' (ç±»å‹: {type(value).__name__})")
            return None
    
    @staticmethod
    def validate_data(df: pd.DataFrame) -> Tuple[bool, str]:
        """
        éªŒè¯æ•°æ®å®Œæ•´æ€§
        
        Args:
            df: DataFrame
            
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        # æ£€æŸ¥å¿…è¦åˆ—
        required_columns = ['stock_code', 'stock_name']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            return False, f"ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing_columns)}"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if len(df) == 0:
            return False, "Excelæ–‡ä»¶ä¸­æ²¡æœ‰æ•°æ®"
        
        # æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æœ‰æ•ˆ
        invalid_codes = df[df['stock_code'].isna() | (df['stock_code'] == '')]
        if len(invalid_codes) > 0:
            return False, f"å­˜åœ¨æ— æ•ˆçš„è‚¡ç¥¨ä»£ç ï¼Œå…± {len(invalid_codes)} æ¡"
        
        return True, "æ•°æ®éªŒè¯é€šè¿‡"

